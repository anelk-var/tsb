% !TEX TS-program = pdflatex
% !TEX encoding = UTF-8 Unicode

% This is a simple template for a LaTeX document using the "article" class.
% See "book", "report", "letter" for other types of document.

\documentclass[11pt]{article} % use larger type; default would be 10pt

\usepackage[utf8]{inputenc} % set input encoding (not needed with XeLaTeX)

%%% Examples of Article customizations
% These packages are optional, depending whether you want the features they provide.
% See the LaTeX Companion or other references for full information.

%%% PAGE DIMENSIONS
\usepackage{geometry} % to change the page dimensions
\geometry{a4paper} % or letterpaper (US) or a5paper or....
% \geometry{margin=2in} % for example, change the margins to 2 inches all round
% \geometry{landscape} % set up the page for landscape
%   read geometry.pdf for detailed page layout information

\usepackage{graphicx} % support the \includegraphics command and options

% \usepackage[parfill]{parskip} % Activate to begin paragraphs with an empty line rather than an indent

%%% PACKAGES
\usepackage{booktabs} % for much better looking tables
\usepackage{array} % for better arrays (eg matrices) in maths
\usepackage{paralist} % very flexible & customisable lists (eg. enumerate/itemize, etc.)
\usepackage{verbatim} % adds environment for commenting out blocks of text & for better verbatim
\usepackage{subfig} % make it possible to include more than one captioned figure/table in a single float
% These packages are all incorporated in the memoir class to one degree or another...

%%% HEADERS & FOOTERS
\usepackage{fancyhdr} % This should be set AFTER setting up the page geometry
\pagestyle{fancy} % options: empty , plain , fancy
\renewcommand{\headrulewidth}{0pt} % customise the layout...
\lhead{}\chead{}\rhead{}
\lfoot{}\cfoot{\thepage}\rfoot{}

%%% SECTION TITLE APPEARANCE
\usepackage{sectsty}
\allsectionsfont{\sffamily\mdseries\upshape} % (See the fntguide.pdf for font help)
% (This matches ConTeXt defaults)

%%% ToC (table of contents) APPEARANCE
\usepackage[nottoc,notlof,notlot]{tocbibind} % Put the bibliography in the ToC
\usepackage[titles,subfigure]{tocloft} % Alter the style of the Table of Contents
\renewcommand{\cftsecfont}{\rmfamily\mdseries\upshape}
\renewcommand{\cftsecpagefont}{\rmfamily\mdseries\upshape} % No bold!

%%% END Article customizations

%%% The "real" document content comes below...

\title{Document alignment from multiple views}
\author{Venkatesh, Akhilesh and Arpit}
\date{Roll numbers} % Activate to display a given date or no date (if empty),
         % otherwise the current date is printed 

\begin{document}
\maketitle
\abstract{We consider the problem of aligning regions of documents by their semantic relevance. 
Our specific target is to align presentation slides with the original text.
We model this as a supervised learning problem and use some labeled data to learn its parameters.
We describe the data collected, procedure to label it, the model fitting and evaluation, and inference.}

\section{Introduction}
Consider a pair of documents containing the same information; a classical problem with multiple views of the same information. 
The problem is to align regions of the two documents by their semantic equivalence.
Regions can be split of the document to any granularity.
We specifically consider the case of presentations of textual descriptions.
Text from either books or research papers is one view of the information that has detailed explanations.
Presentations are another view of this information in a condensed format.
Information in the two views are not necessarily same but have a strong overlap between them.

 
The problem of inferring semantic relevance of documents is classical in natural language processing and continues to be challenging.
Numerous methods have been proposed to capture semantics of natural language~(see, for example, \cite{jurafsky_book08, mikolov_interspeech10, deerwester_jinsci90}).
We begin with the simplest model by using the word occurrences  to match regions of different views.
But this can be extended by using latent models or continuous space representations to actually match semantics.

\subsection{Related work}
Little prior work has been done in the literature on document alignment using multi-view models.
The works of~\cite{koiti_capp99} and~\cite{beamer_acl09} study this for the purpose of generating slides.
\cite{koiti_capp99} use rules-based method to compose slides from a given rather than learning an alignment from some training data.
\cite{beamer_acl09} use Euclidean distances between features to align regions.
They try part-of-speech tags and other linguistic features and test importance of query expansion to this application.

We instead model is as a supervised learning problem and use some labeled data to learn a model to aligning relevant regions.
We describe collection of data and the models we consider in the next section.

%Numerous methods have been proposed to capture word semantics explicitly by using a continuous space representations like, for example, .

%In the next
\section{Data collection, labeling and feature representation}
Write briefly about data, labels and tf-idf features.

We use term frequency-inverse document frequency (tf-idf) features for our baseline experiment.
Tf-idf features weigh a word $w$ in region $d$ by its importance measured as,
tfidf$(w,d)$ = tf$(w,d)\times$idf$(w)$ where 
tf$(w,d)=$ frequency of $w$ relative to max. of any word in $d$.\\
idf$(w)=$ inverse fraction of all documents containing word $w$.

\section{Modeling}
The simplest model we consider is Canonical Correlation Analysis~(CCA, see \cite{hastie_book, bishop_book}).
CCA transforms both views into two different spaces where the transformed features best display the correlations.
CCA is know to be the same a reducing the rank of the original design matrix and then performing regression and hence the name reduced rank regression.
A simple alternative to CCA would be to concatenate features of the two views and perform principal component analysis as necessary.

This reduced feature set from with CCA or PCA is then put into a binary classification framework where we consider all pairs of the two views and assign class $1$ to those that are relevant from the labeling and $-1$ otherwise.
We then fit a simple classifier to the resulting data.

\bibliographystyle{plain}
\bibliography{cref}
\end{document}
